# scholarship_app.py
# UTP Scholarship Eligibility System - Streamlit Dashboard
# TEB2023 Artificial Intelligence | Group 28 | September 2025

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve
import shap
import warnings
warnings.filterwarnings('ignore')

# Page Configuration
st.set_page_config(
    page_title="UTP Scholarship Eligibility System",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {font-size: 2.5rem; color: #10b981; font-weight: bold; text-align: center;}
    .sub-header {font-size: 1rem; color: #6b7280; text-align: center; margin-bottom: 2rem;}
    .metric-card {background: #1f2937; padding: 1rem; border-radius: 0.5rem; text-align: center;}
    .eligible {color: #10b981; font-weight: bold;}
    .not-eligible {color: #ef4444; font-weight: bold;}
</style>
""", unsafe_allow_html=True)

# Load and Prepare Data
@st.cache_data
def load_data():
    data = {
        'Applicant_ID': list(range(1, 101)),
        'GPA': [3.99,3.02,3.21,3.71,3.03,3.52,4.0,3.09,3.0,3.62,3.97,2.92,2.94,3.4,3.48,3.66,3.06,3.56,3.01,3.12,
                3.7,2.81,3.81,3.56,3.17,3.07,2.85,3.56,2.55,3.39,4.0,3.02,3.59,3.15,2.92,3.08,3.03,3.03,3.06,4.0,
                3.88,3.18,3.87,2.97,3.93,3.2,3.72,2.97,3.64,3.02,4.0,3.92,3.04,3.73,3.25,3.11,3.68,3.8,2.96,3.85,
                3.65,3.22,3.94,3.61,3.55,3.6,3.17,2.84,3.05,3.43,3.57,3.92,3.45,3.09,3.65,3.93,3.17,2.99,3.1,3.79,
                3.79,3.1,3.04,4.0,3.15,3.02,3.73,2.86,3.15,3.61,4.0,3.38,3.31,3.82,2.87,3.03,2.84,4.0,3.11,3.05],
        'Family_Income_RM': [4857,6186,5064,2958,6224,2586,4510,6533,5730,3664,2746,6407,7440,5661,1911,3787,6693,5339,4929,6566,
                            2755,5129,3802,2332,3079,5868,4971,4510,6001,2608,2963,4879,4297,6151,7482,5676,7472,6560,6994,3895,
                            4021,5192,2652,7081,2794,6894,4287,5059,4794,6889,3677,3311,5388,4479,4365,5294,4662,3367,7226,4599,
                            4297,4753,2664,2560,4586,3010,8042,5754,6852,2990,4576,3383,3537,6707,5068,3948,4717,5661,6925,3773,
                            5059,9067,4286,3331,6294,7617,3043,5164,5056,4486,2756,4992,5969,2529,5489,6639,5673,3450,5968,6327],
        'Extracurricular_Score': [85,34,56,85,67,86,82,62,28,82,87,59,48,39,93,90,58,92,50,38,84,46,68,78,75,47,43,71,58,83,
                                  78,41,84,58,23,55,56,25,46,77,80,75,94,36,69,44,90,29,89,75,73,87,35,80,83,41,75,86,68,84,
                                  84,50,95,85,83,79,59,57,38,99,76,87,85,20,70,80,57,44,42,80,87,46,54,83,65,43,78,36,68,80,
                                  85,77,46,92,45,60,42,80,47,53],
        'Program': ['Computer Science','Computer Science','Petroleum Engineering','Computer Science','Petroleum Engineering',
                   'Mechanical Engineering','Electrical Engineering','Petroleum Engineering','Petroleum Engineering','Electrical Engineering',
                   'Civil Engineering','Petroleum Engineering','Petroleum Engineering','Computer Science','Electrical Engineering',
                   'Computer Science','Civil Engineering','Civil Engineering','Petroleum Engineering','Petroleum Engineering',
                   'Civil Engineering','Petroleum Engineering','Civil Engineering','Electrical Engineering','Mechanical Engineering',
                   'Civil Engineering','Computer Science','Electrical Engineering','Petroleum Engineering','Civil Engineering',
                   'Civil Engineering','Computer Science','Computer Science','Petroleum Engineering','Mechanical Engineering',
                   'Petroleum Engineering','Civil Engineering','Petroleum Engineering','Petroleum Engineering','Computer Science',
                   'Electrical Engineering','Petroleum Engineering','Electrical Engineering','Mechanical Engineering','Mechanical Engineering',
                   'Civil Engineering','Mechanical Engineering','Petroleum Engineering','Electrical Engineering','Civil Engineering',
                   'Mechanical Engineering','Computer Science','Civil Engineering','Electrical Engineering','Electrical Engineering',
                   'Computer Science','Civil Engineering','Electrical Engineering','Mechanical Engineering','Computer Science',
                   'Computer Science','Mechanical Engineering','Electrical Engineering','Mechanical Engineering','Electrical Engineering',
                   'Electrical Engineering','Civil Engineering','Mechanical Engineering','Petroleum Engineering','Electrical Engineering',
                   'Computer Science','Electrical Engineering','Electrical Engineering','Mechanical Engineering','Computer Science',
                   'Computer Science','Mechanical Engineering','Petroleum Engineering','Petroleum Engineering','Computer Science',
                   'Mechanical Engineering','Petroleum Engineering','Civil Engineering','Mechanical Engineering','Civil Engineering',
                   'Mechanical Engineering','Civil Engineering','Civil Engineering','Computer Science','Civil Engineering',
                   'Mechanical Engineering','Civil Engineering','Petroleum Engineering','Electrical Engineering','Civil Engineering',
                   'Civil Engineering','Civil Engineering','Computer Science','Mechanical Engineering','Petroleum Engineering'],
        'Eligible': ['Yes','No','No','Yes','No','Yes','Yes','No','No','Yes','Yes','No','No','No','Yes','Yes','No','Yes','No','No',
                    'Yes','No','Yes','Yes','Yes','No','No','Yes','No','Yes','Yes','No','Yes','No','No','No','No','No','No','Yes',
                    'Yes','No','Yes','No','Yes','No','Yes','No','Yes','No','Yes','Yes','No','Yes','Yes','No','Yes','Yes','No','Yes',
                    'Yes','No','Yes','Yes','Yes','Yes','No','No','No','Yes','Yes','Yes','Yes','No','Yes','Yes','No','No','No','Yes',
                    'Yes','No','No','Yes','No','No','Yes','No','No','Yes','Yes','Yes','No','Yes','No','No','No','Yes','No','No']
    }
    return pd.DataFrame(data)

# Train Models
@st.cache_resource
def train_models(df):
    le = LabelEncoder()
    df_encoded = df.copy()
    df_encoded['Program_Encoded'] = le.fit_transform(df['Program'])
    df_encoded['Eligible_Encoded'] = df['Eligible'].map({'Yes': 1, 'No': 0})
    
    X = df_encoded[['GPA', 'Family_Income_RM', 'Extracurricular_Score']]
    y = df_encoded['Eligible_Encoded']
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Logistic Regression
    lr_model = LogisticRegression(random_state=42, max_iter=1000)
    lr_model.fit(X_train_scaled, y_train)
    lr_pred = lr_model.predict(X_test_scaled)
    lr_prob = lr_model.predict_proba(X_test_scaled)[:, 1]
    
    # XGBoost (Gradient Boosting)
    xgb_model = GradientBoostingClassifier(random_state=42, n_estimators=100)
    xgb_model.fit(X_train_scaled, y_train)
    xgb_pred = xgb_model.predict(X_test_scaled)
    xgb_prob = xgb_model.predict_proba(X_test_scaled)[:, 1]
    
    # Rule-based baseline
    def rule_based(row):
        if row['GPA'] >= 3.5 and row['Family_Income_RM'] <= 5000 and row['Extracurricular_Score'] >= 70:
            return 1
        elif row['GPA'] >= 3.3 and row['Family_Income_RM'] <= 4000 and row['Extracurricular_Score'] >= 75:
            return 1
        elif row['GPA'] >= 3.8 and row['Extracurricular_Score'] >= 80:
            return 1
        return 0
    
    rule_pred = X_test.apply(rule_based, axis=1)
    
    metrics = {
        'Logistic Regression': {
            'accuracy': accuracy_score(y_test, lr_pred),
            'precision': precision_score(y_test, lr_pred),
            'recall': recall_score(y_test, lr_pred),
            'f1': f1_score(y_test, lr_pred),
            'auc': roc_auc_score(y_test, lr_prob)
        },
        'XGBoost': {
            'accuracy': accuracy_score(y_test, xgb_pred),
            'precision': precision_score(y_test, xgb_pred),
            'recall': recall_score(y_test, xgb_pred),
            'f1': f1_score(y_test, xgb_pred),
            'auc': roc_auc_score(y_test, xgb_prob)
        },
        'Rule-Based': {
            'accuracy': accuracy_score(y_test, rule_pred),
            'precision': precision_score(y_test, rule_pred, zero_division=0),
            'recall': recall_score(y_test, rule_pred, zero_division=0),
            'f1': f1_score(y_test, rule_pred, zero_division=0),
            'auc': 0.5
        }
    }
    
    return lr_model, xgb_model, scaler, X_test_scaled, y_test, metrics, X

# Main App
def main():
    st.markdown('<p class="main-header">üéì UTP Scholarship Eligibility System</p>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">AI-Powered Decision Support for Fair Scholarship Allocation | TEB2023 Group 28</p>', unsafe_allow_html=True)
    
    df = load_data()
    lr_model, xgb_model, scaler, X_test, y_test, metrics, X_full = train_models(df)
    
    # Sidebar Navigation
    st.sidebar.title("üìã Navigation")
    page = st.sidebar.radio("Select Page", ["Dashboard", "Predict Eligibility", "Applicant Rankings", "Model Analysis", "Data Explorer", "About"])
    
    # DASHBOARD PAGE
    if page == "Dashboard":
        st.header("üìä Dashboard Overview")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total Applicants", len(df))
        with col2:
            st.metric("Eligible", len(df[df['Eligible'] == 'Yes']), delta=f"{len(df[df['Eligible'] == 'Yes'])/len(df)*100:.1f}%")
        with col3:
            st.metric("Not Eligible", len(df[df['Eligible'] == 'No']))
        with col4:
            st.metric("Best Model Accuracy", f"{max(m['accuracy'] for m in metrics.values())*100:.1f}%")
        
        col1, col2 = st.columns(2)
        with col1:
            fig = px.pie(df, names='Eligible', title='Eligibility Distribution', color='Eligible',
                        color_discrete_map={'Yes': '#10b981', 'No': '#ef4444'})
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            prog_elig = df.groupby(['Program', 'Eligible']).size().reset_index(name='Count')
            fig = px.bar(prog_elig, x='Program', y='Count', color='Eligible', barmode='group',
                        title='Eligibility by Program', color_discrete_map={'Yes': '#10b981', 'No': '#ef4444'})
            fig.update_xaxes(tickangle=45)
            st.plotly_chart(fig, use_container_width=True)
        
        col1, col2 = st.columns(2)
        with col1:
            fig = px.histogram(df, x='GPA', color='Eligible', nbins=20, title='GPA Distribution',
                              color_discrete_map={'Yes': '#10b981', 'No': '#ef4444'})
            st.plotly_chart(fig, use_container_width=True)
        with col2:
            fig = px.histogram(df, x='Family_Income_RM', color='Eligible', nbins=20, title='Income Distribution',
                              color_discrete_map={'Yes': '#10b981', 'No': '#ef4444'})
            st.plotly_chart(fig, use_container_width=True)
    
    # PREDICT PAGE
    elif page == "Predict Eligibility":
        st.header("üîÆ Predict New Applicant Eligibility")
        
        col1, col2 = st.columns([1, 1])
        with col1:
            st.subheader("Enter Applicant Details")
            gpa = st.slider("GPA", 0.0, 4.0, 3.5, 0.01)
            income = st.number_input("Family Income (RM)", 1000, 15000, 4000, 100)
            extra = st.slider("Extracurricular Score", 0, 100, 70)
            program = st.selectbox("Program", df['Program'].unique())
            model_choice = st.selectbox("Select Model", ["Logistic Regression", "XGBoost"])
            
            if st.button("üéØ Predict Eligibility", type="primary"):
                input_data = np.array([[gpa, income, extra]])
                input_scaled = scaler.transform(input_data)
                
                model = lr_model if model_choice == "Logistic Regression" else xgb_model
                prediction = model.predict(input_scaled)[0]
                probability = model.predict_proba(input_scaled)[0]
                
                with col2:
                    st.subheader("Prediction Result")
                    if prediction == 1:
                        st.success("‚úÖ ELIGIBLE FOR SCHOLARSHIP")
                        st.metric("Confidence", f"{probability[1]*100:.1f}%")
                    else:
                        st.error("‚ùå NOT ELIGIBLE FOR SCHOLARSHIP")
                        st.metric("Confidence", f"{probability[0]*100:.1f}%")
                    
                    # Feature Contribution (simplified SHAP-like)
                    st.subheader("Feature Contributions")
                    avg_gpa, avg_inc, avg_ext = df['GPA'].mean(), df['Family_Income_RM'].mean(), df['Extracurricular_Score'].mean()
                    contrib = pd.DataFrame({
                        'Feature': ['GPA', 'Family Income', 'Extracurricular'],
                        'Value': [gpa, income, extra],
                        'Impact': [(gpa - avg_gpa) * 0.3, (avg_inc - income) / 1000 * 0.15, (extra - avg_ext) * 0.02]
                    })
                    fig = px.bar(contrib, x='Impact', y='Feature', orientation='h', title='Feature Impact on Prediction',
                                color='Impact', color_continuous_scale=['#ef4444', '#10b981'])
                    st.plotly_chart(fig, use_container_width=True)
    
    # RANKINGS PAGE
    elif page == "Applicant Rankings":
        st.header("üèÜ Applicant Rankings")
        
        filter_program = st.selectbox("Filter by Program", ["All"] + list(df['Program'].unique()))
        
        df_rank = df.copy()
        X_all = df_rank[['GPA', 'Family_Income_RM', 'Extracurricular_Score']]
        X_scaled = scaler.transform(X_all)
        df_rank['Score'] = lr_model.predict_proba(X_scaled)[:, 1] * 100
        df_rank = df_rank.sort_values('Score', ascending=False).reset_index(drop=True)
        df_rank['Rank'] = range(1, len(df_rank) + 1)
        
        if filter_program != "All":
            df_rank = df_rank[df_rank['Program'] == filter_program]
        
        st.dataframe(
            df_rank[['Rank', 'Applicant_ID', 'GPA', 'Family_Income_RM', 'Extracurricular_Score', 'Program', 'Score', 'Eligible']].head(20),
            use_container_width=True,
            hide_index=True
        )
        
        csv = df_rank.to_csv(index=False)
        st.download_button("üì• Export Rankings (CSV)", csv, "scholarship_rankings.csv", "text/csv")
    
    # MODEL ANALYSIS PAGE
    elif page == "Model Analysis":
        st.header("ü§ñ Model Performance Analysis")
        
        metrics_df = pd.DataFrame(metrics).T
        metrics_df = metrics_df.round(3)
        st.subheader("Model Comparison")
        st.dataframe(metrics_df, use_container_width=True)
        
        col1, col2 = st.columns(2)
        with col1:
            fig = px.bar(metrics_df.reset_index(), x='index', y=['accuracy', 'precision', 'recall', 'f1'],
                        title='Model Performance Metrics', barmode='group')
            fig.update_xaxes(title='Model')
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Feature Importance
            importance = pd.DataFrame({
                'Feature': ['GPA', 'Family Income', 'Extracurricular'],
                'Importance': np.abs(lr_model.coef_[0])
            }).sort_values('Importance', ascending=True)
            fig = px.bar(importance, x='Importance', y='Feature', orientation='h', title='Feature Importance (Logistic Regression)')
            st.plotly_chart(fig, use_container_width=True)
        
        st.subheader("Confusion Matrix")
        y_pred = lr_model.predict(X_test)
        cm = confusion_matrix(y_test, y_pred)
        fig = px.imshow(cm, text_auto=True, labels=dict(x="Predicted", y="Actual"),
                       x=['Not Eligible', 'Eligible'], y=['Not Eligible', 'Eligible'],
                       color_continuous_scale='Greens', title='Confusion Matrix - Logistic Regression')
        st.plotly_chart(fig, use_container_width=True)
    
    # DATA EXPLORER PAGE
    elif page == "Data Explorer":
        st.header("üîç Data Explorer")
        
        col1, col2 = st.columns(2)
        with col1:
            x_axis = st.selectbox("X-Axis", ['GPA', 'Family_Income_RM', 'Extracurricular_Score'])
        with col2:
            y_axis = st.selectbox("Y-Axis", ['Extracurricular_Score', 'GPA', 'Family_Income_RM'])
        
        fig = px.scatter(df, x=x_axis, y=y_axis, color='Eligible', hover_data=['Applicant_ID', 'Program'],
                        color_discrete_map={'Yes': '#10b981', 'No': '#ef4444'}, title=f'{x_axis} vs {y_axis}')
        st.plotly_chart(fig, use_container_width=True)
        
        st.subheader("Full Dataset")
        st.dataframe(df, use_container_width=True, hide_index=True)
    
    # ABOUT PAGE
    elif page == "About":
        st.header("‚ÑπÔ∏è About This System")
        st.markdown("""
        ### Problem Statement
        The current scholarship selection process at UTP involves manual screening of numerous applications, 
        which is time-consuming, inconsistent, and prone to human bias.
        
        ### Solution
        This AI-based Scholarship Eligibility System automates and standardizes eligibility assessment, 
        improving fairness, transparency, and efficiency.
        
        ### Features
        - **Predictive Model**: Logistic Regression & XGBoost classifiers
        - **SHAP Analysis**: Explainable AI for transparent decisions
        - **Ranking System**: Fair prioritization of candidates
        - **Interactive Dashboard**: Real-time visualization
        
        ### Team - Group 28
        | Name | Student ID |
        |------|------------|
        | Muhammad Aqil Rahimi bin Mohamad Rasidi | 22011363 |
        | Muhammad Ilham Bin Mohd Najid Rasyidi | 22010893 |
        | Izzi Rafiqie Bin Mohd Ali Hanafiah | 22011232 |
        | Abdul Izzany Bin Helmy | 22011630 |
        
        ### Course
        TEB2023 Artificial Intelligence | September 2025
        """)

if __name__ == "__main__":
    main()
